# Macroâ€Trading Airflow + Spark Project

Ce projet et une Ã©tude de stratÃ©gie contre-cyclique basÃ©e sur les quadrants Ã©conomiques, avec :

Â°Â° Airflow pour lâ€™orchestration mensuelle Â°Â°
  - RÃ©cupÃ©ration des donnÃ©es macro (FRED) et assets (Yahoo Finance)
  - Nettoyage & mise en forme (mensuel & journalier)
  - Calcul des quadrants (Spark)
  - Calcul de la performance par quadrant (Spark)
  - Backtest de la stratÃ©gie fixe (Spark)
  - Indexation dans Elasticsearch (BashOperator + Python)

Â°Â° Spark (PySpark + Pandas) pour Â°Â°
  - Calcul des quadrants Ã©conomique  (`compute_quadrants.py`)
  - Calcul des performances dâ€™actifs dans chacun des quadrants  (`compute_assets_performance.py`)
  - Backtest de la stratÃ©gie dâ€™allocation d'un portefeuille qui suiverais les meilleur actifs sur chaque quadrant(`backtest_strategy.py`)

Â°Â° Elasticsearch & Kibana pour visualiser Â°Â°
  - Les quadrants et les performances dâ€™actifs
  - La valeur du portefeuille, SP500 et Gold au fil du temps  
  - Les ratios de Sharpe et autres mÃ©triques agrÃ©gÃ©es
 
 âš™ï¸ PrÃ©requis

- **Python 3.8+** (venv recommandÃ©)  
- **Apache Airflow** (2.x) avec Spark provider  
- **Apache Spark** (3.x) et `spark-submit`  
- **Elasticsearch** (8.x) + **Kibana**  
- BibliothÃ¨ques Python : `pandas`, `numpy`, `fredapi`, `yfinance`, `requests`, `elasticsearch`

- ## ğŸš€ Installation & dÃ©ploiement

1. **Cloner le dÃ©pÃ´t** dans `$AIRFLOW_HOME` (ex. `~/airflow`).  
2. **CrÃ©er un virtualenv** et installer les dÃ©pendances :
   ```bash
   cd ~/airflow
   python3 -m venv airflow_venv
   source airflow_venv/bin/activate
   pip install apache-airflow apache-airflow-providers-apache-spark pyspark pandas numpy fredapi yfinance requests elasticsearch
   Airflow standalone


   PS: Ce script est pour les PNL MAKER
   
